<h2><a href=''> Implementation du VGG-16 (CNN) et mise en oeuvre du Transfert Learning pour la Computer Vision </a></h2>
L'objet de notre étude est le célèbre VGG-16, une version du réseau de neurones convolutif très connu appelé VGG-Net. Nous allons d'abord l'implémenter de A à Z pour découvrir <a href='https://keras.io/api/'> Keras </a>, puis nous allons voir comment classifier des images de manière efficace. Pour cela, nous allons exploiter le réseau VGG-16 pré-entraîné fourni par Keras, et mettre en oeuvre le Transfer Learning.
<a href ='https://github.com/JMT-AI/Portfolio/blob/master/7.%20Computer%20Vision/VGG-16_Livrable.ipynb'> En savoir plus </a>


<h2><a href=''> Etude de Churn via un ANN (Réseaux de Neurones Artificiels) </a></h2>
Dans cette étude, il s'agit de trouver la meilleure architecture de réseau de neurones artificiels (garantissant bien sûr un temps de calcul raisonnable sur un PC moyen) pour prédire le churn d'une banque fictive.
<a href ='https://github.com/JMT-AI/Portfolio/blob/master/Artificial_Neural_Networks/ann.py'> En savoir plus </a>


<h2><a href=''> Classification binaire d'animaux domestiques via un CNN (Réseaux de Neurones à Convolution) </a></h2>
On va dans ce sujet mettre en place un système capable de reconnaître la photo d'un chat et d'un chien avec un taux d'erreur de prédiction le plus faible possible. Nous utiliserons une fonction de Keras pour générer beaucoup plus d'images pour bien entrainer notre modèle.
<a href ='https://github.com/JMT-AI/Portfolio/blob/master/Convolutional_Neural_Networks/cnn.py'> En savoir plus </a>


<h2><a href=''> Prédiction (Tentative de modélisation de tendance) du prix de l'action Google via un RNN (Réseaux de Neurones Récurrents). </a></h2>
Bien que le prix d'une action soit une métrique difficile à prédire, nous allons aller plus loin en exploitant la puissance des réseaux de neurones récurrents sur les données du prix de l'action Google entre 2012 et 2016 pour faire une prédiction sur 2017. L'objectif ici n'est pas de prédire la valeur de l'action Google sur 2017 mais de prédire sa <strong> tendance </strong> sur 2017. 
<a href ='https://github.com/JMT-AI/Portfolio/blob/master/Recurrent_Neural_Networks/rnn.py'> En savoir plus </a>


<h2><a href=''> DEEP LEARNING HYBRIDE : Implémentation d'une Carte Auto Adaptive pour la détection de fraude dans une enquête bancaire </a></h2>
Dans cette étude, il s'agit d'une banque qui a reçu d'une partie de ses clients des demandes de cartes de crédit. Pour soumettre leur demande, les clients doivent remplir un formulaire précisant la raison de la demande et différentes informations. La banque, qui a su intégrer le machine learning dans sa stratégie, veut pondérer des décisions (donner ou non la carte de crédit au client après le verdict d'experts sur l'intention du client c'est-à-dire s'il est un fraudeur ou non) avec les informations suggérées par ses données. 
Pour découvrir ces 'informations cachées' nous mettrons en oeuvre premièrement un algorithme de deep learning non-supervisé : la SOM (Self Organizing Map) ou carte auto-adaptative pour découvrir les clients les plus susceptibles de frauder puis deuxièmement nous passerons du non-supervisé au supervisé pour faire des prédictions sur des données de test.
<a href ='https://github.com/JMT-AI/Portfolio/blob/master/Self_Organizing_Maps/mega_study.py'> En savoir plus </a>


<h2><a href=''> Mise en place d'un système de recommandation grâce à une Machine de Boltzmann </a></h2>
Ce travail concerne l'implémentation d'un système de recommandation de films via une machine de Boltzmann. L'objet est d'entraîner une machine de Boltzmann sur un jeu de données (voir <a href = 'https://grouplens.org/datasets/movielens/'> MovieLens </a>) très lourd (25 millions de films notés par les utilisateurs). On va dans un 1er temps se focaliser sur une portion de ce dataset (1 millions de films) pour construire notre machine de Boltzmann en vue de recommander aux clients des films de manière pertinente.
<a href ='https://github.com/JMT-AI/Portfolio/blob/master/Boltzmann_Machines/rbm.py'> En savoir plus </a>   


<h2><a href=''> Mise en place d'un auto encodeur empilé - Système de scoring de films pour la recommandation </a></h2>
<br>
L'objet de ce projet est la mise en place d'un système de scoring de films via un auto encodeur empilé entrainé sur le dataset publié sur <a href = 'https://grouplens.org/datasets/movielens/'> MovieLens </a>. Le système est mis en oeuvre avec <a href='https://pytorch.org/resources/'>PyTorch</a>.
<a href ='https://github.com/JMT-AI/Portfolio/blob/master/AutoEncoders/ae.py'> En savoir plus </a>


### Support or Contact

Having trouble with Pages? Check out our [documentation](https://help.github.com/categories/github-pages-basics/) or [contact support](https://github.com/contact) and we’ll help you sort it out.
